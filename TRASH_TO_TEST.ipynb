{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoload_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jose/Desktop/lucent-things/Results_Bashivan_Inception/ROI_3_Layer_mixed5a/ROI_3_Layer_mixed5a_0_Inception/Bashivan_Inception_3_mixed5a_epoch_13_loss_0.1333842394541893_smoothweight_0.01_sparseweight_1e-08_weightdecay_0.001.pt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindLowestBashivanModelInception(3, 'mixed5a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jose/Desktop/lucent-things/Results_Bashivan_Vgg/ROI_3_Layer_10/ROI_3_Layer_10_0/Bashivan_Vgg_3_10_epoch_12_loss_0.08944599568044988_smoothweight_0.01_sparseweight_1e-08_weightdecay_0.001.pt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindLowestBashivanModelVgg(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jose/Desktop/lucent-things/Results_Cadena_Inception/ROI_10_Layer_conv2d2/ROI_10_Layer_conv2d2_0_/Inception_model_10_conv2d2_epoch_8_loss_0.10019534137015827_sparsity_0.01_smoothness_0.1_groupsparsity_0.001.pt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindLowestCadenaModelInception(10, 'conv2d2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jose/Desktop/lucent-things/Results_Cadena_Vgg/ROI_10_Layer_12/ROI_10_Layer_12_0_Vgg/Vgg_model_10_12_epoch_9_loss_0.19151701668520363_sparsity_0.001_smoothness_0.001_groupsparsity_0.01.pt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindLowestCadenaModelVgg(10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d2\n",
      "RedirectedReluLayer()\n",
      "/home/jose/Desktop/lucent-things/Results_Bashivan_Inception/ROI_3_Layer_conv2d2/ROI_3_Layer_conv2d2_0_Inception/Bashivan_Inception_3_conv2d2_epoch_15_loss_0.11123535863014508_smoothweight_0.01_sparseweight_1e-08_weightdecay_0.001.pt\n",
      "\n",
      "\n",
      "Loaded Bashivan_Inception_3_conv2d2_epoch_15_loss_0.11123535863014508_smoothweight_0.01_sparseweight_1e-08_weightdecay_0.001.pt\n"
     ]
    }
   ],
   "source": [
    "net = BashivanInception(3, 'conv2d2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VggShape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lopez\\Desktop\\lucent-things\\TRASH_TO_TEST.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000000?line=35'>36</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw_shape\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000000?line=38'>39</a>\u001b[0m vgg_pretrained \u001b[39m=\u001b[39m inceptionv1(pretrained \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000000?line=39'>40</a>\u001b[0m vgge \u001b[39m=\u001b[39m VggShape(vgg_pretrained)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000000?line=40'>41</a>\u001b[0m sw \u001b[39m=\u001b[39m vgge\u001b[39m.\u001b[39mshape()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VggShape' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from helper import makeGaussian, FeatureExtractor, fix_parameters, load_sta\n",
    "from lucent.modelzoo import vgg19, util\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class VggShape(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model, conv_layer = 0, num_neurons = 43, device = None):\n",
    "        super(VggShape, self).__init__()\n",
    "\n",
    "        \n",
    "        self.features_to_extract = [0,2,5,7,10,12,14,16,19,21,23,25,28,30,32,34]\n",
    "        self.conv_layer = conv_layer\n",
    "        print('conv_layer:  ', self.conv_layer, type(self.conv_layer))\n",
    "        print('FTE:         ', self.features_to_extract)\n",
    "        print('conv in FTE', self.conv_layer in self.features_to_extract)\n",
    "        print('\\n\\n')\n",
    "\n",
    "        self.vgg_pretrained = pretrained_model\n",
    "        self.ann = fix_parameters(self.vgg_pretrained)\n",
    "        self.feature_extractor = FeatureExtractor(self.ann, layers = ['features.'+str(self.conv_layer)])\n",
    "\n",
    "        dummy_input  = torch.ones(1, 3, 224, 224)\n",
    "        dummy_output = self.feature_extractor(dummy_input)\n",
    "        print(dummy_output.keys(), dummy_output[list(dummy_output.keys())[0]].shape)\n",
    "        dummy_output_shape = list(dummy_output[list(dummy_output.keys())[0]].shape)\n",
    "        self.w_shape = dummy_output_shape[1:] + [num_neurons]\n",
    "        self.w = dummy_output_shape\n",
    "        \n",
    "        \n",
    "    def shape(self):\n",
    "        return self.w\n",
    "    def mod_shape(self):\n",
    "        return self.w_shape\n",
    "\n",
    "    \n",
    "vgg_pretrained = vgg19(pretrained = True)\n",
    "vgge = VggShape(vgg_pretrained)\n",
    "sw = vgge.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.0']) torch.Size([1, 64, 224, 224])\n",
      "features.1\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.1']) torch.Size([1, 64, 224, 224])\n",
      "features.2\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.2']) torch.Size([1, 64, 224, 224])\n",
      "features.3\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.3']) torch.Size([1, 64, 224, 224])\n",
      "features.4\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "dict_keys(['features.4']) torch.Size([1, 64, 112, 112])\n",
      "features.5\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.5']) torch.Size([1, 128, 112, 112])\n",
      "features.6\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.6']) torch.Size([1, 128, 112, 112])\n",
      "features.7\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.7']) torch.Size([1, 128, 112, 112])\n",
      "features.8\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.8']) torch.Size([1, 128, 112, 112])\n",
      "features.9\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "dict_keys(['features.9']) torch.Size([1, 128, 56, 56])\n",
      "features.10\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.10']) torch.Size([1, 256, 56, 56])\n",
      "features.11\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.11']) torch.Size([1, 256, 56, 56])\n",
      "features.12\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.12']) torch.Size([1, 256, 56, 56])\n",
      "features.13\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.13']) torch.Size([1, 256, 56, 56])\n",
      "features.14\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.14']) torch.Size([1, 256, 56, 56])\n",
      "features.15\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.15']) torch.Size([1, 256, 56, 56])\n",
      "features.16\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.16']) torch.Size([1, 256, 56, 56])\n",
      "features.17\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.17']) torch.Size([1, 256, 56, 56])\n",
      "features.18\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "dict_keys(['features.18']) torch.Size([1, 256, 28, 28])\n",
      "features.19\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.19']) torch.Size([1, 512, 28, 28])\n",
      "features.20\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.20']) torch.Size([1, 512, 28, 28])\n",
      "features.21\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.21']) torch.Size([1, 512, 28, 28])\n",
      "features.22\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.22']) torch.Size([1, 512, 28, 28])\n",
      "features.23\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.23']) torch.Size([1, 512, 28, 28])\n",
      "features.24\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.24']) torch.Size([1, 512, 28, 28])\n",
      "features.25\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.25']) torch.Size([1, 512, 28, 28])\n",
      "features.26\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.26']) torch.Size([1, 512, 28, 28])\n",
      "features.27\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "dict_keys(['features.27']) torch.Size([1, 512, 14, 14])\n",
      "features.28\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.28']) torch.Size([1, 512, 14, 14])\n",
      "features.29\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.29']) torch.Size([1, 512, 14, 14])\n",
      "features.30\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.30']) torch.Size([1, 512, 14, 14])\n",
      "features.31\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.31']) torch.Size([1, 512, 14, 14])\n",
      "features.32\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.32']) torch.Size([1, 512, 14, 14])\n",
      "features.33\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.33']) torch.Size([1, 512, 14, 14])\n",
      "features.34\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "dict_keys(['features.34']) torch.Size([1, 512, 14, 14])\n",
      "features.35\n",
      "ReLU(inplace=True)\n",
      "dict_keys(['features.35']) torch.Size([1, 512, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "shapes       = []\n",
    "shapes_dummy = []\n",
    "for i in range(36):\n",
    "    vgge = VggShape(vgg_pretrained, conv_layer = i)\n",
    "    shapes.append(vgge.shape())\n",
    "    shapes_dummy.append(vgge.mod_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 64, 224, 224],\n",
       " [1, 64, 224, 224],\n",
       " [1, 64, 224, 224],\n",
       " [1, 64, 224, 224],\n",
       " [1, 64, 112, 112],\n",
       " [1, 128, 112, 112],\n",
       " [1, 128, 112, 112],\n",
       " [1, 128, 112, 112],\n",
       " [1, 128, 112, 112],\n",
       " [1, 128, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 56, 56],\n",
       " [1, 256, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 28, 28],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14],\n",
       " [1, 512, 14, 14]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[64, 224, 224, 43],\n",
       " [64, 224, 224, 43],\n",
       " [64, 224, 224, 43],\n",
       " [64, 224, 224, 43],\n",
       " [64, 112, 112, 43],\n",
       " [128, 112, 112, 43],\n",
       " [128, 112, 112, 43],\n",
       " [128, 112, 112, 43],\n",
       " [128, 112, 112, 43],\n",
       " [128, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 56, 56, 43],\n",
       " [256, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 28, 28, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43],\n",
       " [512, 14, 14, 43]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lopez\\Anaconda3\\envs\\test_install_cuda_with_pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 32, kernel_size=(13, 13), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "Image shape:    torch.Size([54, 3, 40, 40])\n",
      "Results shape:   torch.Size([54, 32, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "import hashlib\n",
    "import inspect\n",
    "import random\n",
    "#from cnn_sys_ident.utils import *\n",
    "#from cnn_sys_ident.base import Model\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    #def __init__(self, in_channels,  out_channels, kernel_sizes, strides, paddings, smooth_weights, sparse_weights) -> None:\n",
    "    def __init__(self, in_channels,  out_channels, kernel_sizes, n_neurons, strides = [1,1,1], paddings = ['valid', 'same', 'same'], ) -> None:\n",
    "        super(nn.Module, self).__init__()\n",
    "        \n",
    "        assert len(kernel_sizes) == len(out_channels) == len(strides) == len(paddings)\n",
    "        #assert len(paddings) == len(smooth_weights) == len(sparse_weights)\n",
    "        #self.elu = torch.nn.functional.elu()\n",
    "\n",
    "        self.W = []\n",
    "        self.conv_layers = []\n",
    "        self.readout_sparseness_regularizer = 0.0\n",
    "\n",
    "        for i, (in_channel,\n",
    "                out_channel,\n",
    "                kernel_size, \n",
    "                stride, \n",
    "                padding,\n",
    "                ) in enumerate(zip(in_channels, \n",
    "                                            out_channels,\n",
    "                                            kernel_sizes,\n",
    "                                            strides,\n",
    "                                            paddings,)):\n",
    "            self.conv_layers.append(torch.nn.Conv2d(in_channel, \n",
    "                                               out_channel,\n",
    "                                               kernel_size,\n",
    "                                               ))\n",
    "            \n",
    "        for i in self.conv_layers: print(i)\n",
    "\n",
    "        #print(self.conv_layers[-1].shape)\n",
    "        #for j in dir(self.conv_layers[-1]):\n",
    "        #    print(j)\n",
    "\n",
    "        block = '''x = [1,1,1] # pa borrar\n",
    "\n",
    "        px_x_conv = x.shape[-2]\n",
    "        px_y_conv = x.shape[-1]\n",
    "        px_conv   = px_x_conv * px_y_conv\n",
    "\n",
    "        self.conv_flat      = ()\n",
    "\n",
    "        self.W_spatial      = torch.zeros(px_conv, n_neurons)\n",
    "        self.W_spatial      = nn.Parameter(torch.nn.init.trunc_normal_(self.W_spatial, 0, 0.01))\n",
    "        self.W_spatial_flat = self.W_spatial.view(px_conv, 1, 1, n_neurons)\n",
    "\n",
    "        self.W_features     = torch.nn.init.trunc_normal_(torch.zeros((out_channels[-1], n_neurons)), 0, 0.01)\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "            x = torch.nn.functional.elu(x)\n",
    "            bn = nn.BatchNorm2d(x.shape[1])\n",
    "            x = bn(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "######################################################\n",
    "######################################################\n",
    "######################################################\n",
    "\n",
    "\n",
    "test = 1\n",
    "\n",
    "if test:\n",
    "\n",
    "    from torchvision import datasets, transforms\n",
    "    from torchvision.io import read_image\n",
    "    import PIL\n",
    "    \n",
    "    in_channels = [3, 32, 32]\n",
    "    out_channels = [32,32,32]\n",
    "    kernel_sizes = [13,3, 3]\n",
    "    strides = [1,1,1]\n",
    "    cn = ConvNet(in_channels, out_channels, kernel_sizes, n_neurons=43)\n",
    "\n",
    "    #-----------------------\n",
    "\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize(40),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    imgs_path      = 'E:/Jose/Data/THINGS_imgs/train/'\n",
    "    val_imgs_path  = 'E:/Jose/Data/THINGS_imgs/val/'\n",
    "\n",
    "    dataset = datasets.ImageFolder(imgs_path, transform=transform)\n",
    "    dataset_val = datasets.ImageFolder(val_imgs_path, transform=transform)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=54, shuffle=False)\n",
    "    #print(dataset)\n",
    "\n",
    "    im, _ = next(iter(dataloader))\n",
    "    print('Image shape:   ', im.shape)\n",
    "    \n",
    "    result = cn.forward(im)\n",
    "    print('Results shape:  ', result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 32, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "ex = np.random.rand(54, 32, 24, 24)\n",
    "ex.reshape(-1, 576, 32, 1)\n",
    "print(ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_spatial = np.random.rand(576, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [43, 1, 1, 169], expected input[54, 169, 32, 1] to have 1 channels, but got 169 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lopez\\Desktop\\lucent-things\\TRASH_TO_TEST.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000021?line=3'>4</a>\u001b[0m conv_flat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m54\u001b[39m, \u001b[39m169\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000021?line=4'>5</a>\u001b[0m w_spatial_flat  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m43\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m169\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lopez/Desktop/lucent-things/TRASH_TO_TEST.ipynb#ch0000021?line=6'>7</a>\u001b[0m torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mconv2d(conv_flat, w_spatial_flat)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [43, 1, 1, 169], expected input[54, 169, 32, 1] to have 1 channels, but got 169 channels instead"
     ]
    }
   ],
   "source": [
    "conv_flat = torch.randn(54, 32, 1, 169)\n",
    "w_spatial_flat  = torch.randn(169, 1,1,43)\n",
    "\n",
    "conv_flat = torch.randn(54, 169, 32, 1)\n",
    "w_spatial_flat  = torch.randn(43,1,1,169)\n",
    "\n",
    "torch.nn.functional.conv2d(conv_flat, w_spatial_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 169, 32, 1)     (55, 169, 1, 1)            torch.Size([54, 55, 32, 1])\n",
      "(54, 169, 32, 1)     (55, 169, 1, 1)            torch.Size([54, 55, 32, 1])\n",
      "(54, 169, 1, 32)     (55, 169, 1, 1)            torch.Size([54, 55, 1, 32])\n",
      "(54, 169, 1, 32)     (55, 169, 1, 1)            torch.Size([54, 55, 1, 32])\n",
      "(54, 1, 169, 32)     (169, 1, 55, 1)            torch.Size([54, 169, 115, 32])\n",
      "(54, 1, 169, 32)     (169, 1, 55, 1)            torch.Size([54, 169, 115, 32])\n",
      "(54, 1, 169, 32)     (55, 1, 169, 1)            torch.Size([54, 55, 1, 32])\n",
      "(54, 1, 169, 32)     (55, 1, 169, 1)            torch.Size([54, 55, 1, 32])\n",
      "(54, 1, 32, 169)     (169, 1, 1, 55)            torch.Size([54, 169, 32, 115])\n",
      "(54, 1, 32, 169)     (169, 1, 1, 55)            torch.Size([54, 169, 32, 115])\n",
      "(54, 1, 32, 169)     (55, 1, 1, 169)            torch.Size([54, 55, 32, 1])\n",
      "(54, 1, 32, 169)     (55, 1, 1, 169)            torch.Size([54, 55, 32, 1])\n",
      "(32, 169, 54, 1)     (55, 169, 1, 1)            torch.Size([32, 55, 54, 1])\n",
      "(32, 169, 54, 1)     (55, 169, 1, 1)            torch.Size([32, 55, 54, 1])\n",
      "(32, 169, 1, 54)     (55, 169, 1, 1)            torch.Size([32, 55, 1, 54])\n",
      "(32, 169, 1, 54)     (55, 169, 1, 1)            torch.Size([32, 55, 1, 54])\n",
      "(32, 1, 54, 169)     (169, 1, 1, 55)            torch.Size([32, 169, 54, 115])\n",
      "(32, 1, 54, 169)     (169, 1, 1, 55)            torch.Size([32, 169, 54, 115])\n",
      "(32, 1, 54, 169)     (55, 1, 1, 169)            torch.Size([32, 55, 54, 1])\n",
      "(32, 1, 54, 169)     (55, 1, 1, 169)            torch.Size([32, 55, 54, 1])\n",
      "(32, 1, 169, 54)     (169, 1, 55, 1)            torch.Size([32, 169, 115, 54])\n",
      "(32, 1, 169, 54)     (169, 1, 55, 1)            torch.Size([32, 169, 115, 54])\n",
      "(32, 1, 169, 54)     (55, 1, 169, 1)            torch.Size([32, 55, 1, 54])\n",
      "(32, 1, 169, 54)     (55, 1, 169, 1)            torch.Size([32, 55, 1, 54])\n",
      "(1, 169, 54, 32)     (55, 169, 1, 1)            torch.Size([1, 55, 54, 32])\n",
      "(1, 169, 54, 32)     (55, 169, 1, 1)            torch.Size([1, 55, 54, 32])\n",
      "(1, 169, 32, 54)     (55, 169, 1, 1)            torch.Size([1, 55, 32, 54])\n",
      "(1, 169, 32, 54)     (55, 169, 1, 1)            torch.Size([1, 55, 32, 54])\n",
      "28 / 576\n"
     ]
    }
   ],
   "source": [
    "# ALL OPTIONS APPEAR DOWN HERE,USED SHAPES MARKED IN BLUE\n",
    "options, correct = 0, 0\n",
    "for i in itertools.permutations([54, 169, 32, 1]):\n",
    "    for j in itertools.permutations([169, 1, 1, 55]):\n",
    "        conv_flat = torch.randn(*i)\n",
    "        w_spatial_flat  = torch.randn(*j)\n",
    "        options = options+1\n",
    "        try:\n",
    "            result = torch.nn.functional.conv2d(conv_flat, w_spatial_flat)\n",
    "            print(i, '   ', j, '          ', result.shape)\n",
    "            correct = correct +1\n",
    "        except:\n",
    "            pass\n",
    "print(correct, '/', options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(54, 1, 32, 55), dtype=float32, numpy=\n",
       "array([[[[ 1.60412036e-03,  4.17214964e-04, -3.73215618e-04, ...,\n",
       "           1.65351469e-03,  2.95185571e-04,  2.59165675e-03],\n",
       "         [ 1.90500182e-03,  1.70033216e-03,  1.61419064e-03, ...,\n",
       "           1.30022840e-06, -8.09307327e-04, -9.50414804e-04],\n",
       "         [ 5.85827147e-05,  9.90169865e-05, -2.43460783e-03, ...,\n",
       "          -2.77141789e-05,  2.42563151e-03,  7.45375350e-04],\n",
       "         ...,\n",
       "         [ 1.21857971e-03,  5.39551140e-04, -1.12430309e-03, ...,\n",
       "          -5.12155646e-04, -1.27393228e-03, -9.55212963e-05],\n",
       "         [ 2.88109673e-04,  3.74002033e-04, -2.92462966e-04, ...,\n",
       "           1.62687106e-03, -7.09999062e-04,  3.04017420e-04],\n",
       "         [ 2.44027426e-04, -2.86044611e-04, -8.09413963e-04, ...,\n",
       "          -1.17639406e-03, -1.10159116e-03,  1.59233809e-04]]],\n",
       "\n",
       "\n",
       "       [[[ 8.02094291e-05, -5.22078830e-04, -5.40507390e-05, ...,\n",
       "           3.65371793e-03, -4.53522603e-04,  2.61045090e-04],\n",
       "         [ 3.09503084e-04,  1.35283219e-03,  3.62823531e-03, ...,\n",
       "          -7.29332503e-04, -2.27894401e-03,  4.58788127e-04],\n",
       "         [ 7.92859009e-06, -1.40342221e-03, -6.57252502e-04, ...,\n",
       "           1.21090573e-03, -3.89729190e-04, -1.01792184e-03],\n",
       "         ...,\n",
       "         [-2.45709158e-03, -8.73684941e-04,  4.57890658e-03, ...,\n",
       "           3.18301434e-04, -1.60730537e-03, -9.60156554e-04],\n",
       "         [ 1.60237844e-03, -4.06217674e-04, -1.44116278e-03, ...,\n",
       "          -6.79901103e-04,  1.09307141e-04, -5.34577062e-04],\n",
       "         [ 1.61340053e-03,  8.21181631e-04,  1.21409132e-03, ...,\n",
       "           6.68449720e-05, -9.78702446e-04,  1.80106144e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 6.43490523e-04, -4.20540127e-05,  6.18781894e-04, ...,\n",
       "           4.14781593e-04,  2.88466690e-04,  3.33608972e-04],\n",
       "         [ 1.97194587e-03, -1.09370725e-04,  1.03998859e-03, ...,\n",
       "           9.73488277e-05, -1.27932429e-03,  4.72236221e-04],\n",
       "         [ 1.05204410e-03,  1.95189496e-03,  2.23817668e-04, ...,\n",
       "          -1.76087138e-03,  1.79435010e-03,  1.33104715e-03],\n",
       "         ...,\n",
       "         [ 7.38531759e-04,  1.37560233e-03, -6.98305957e-05, ...,\n",
       "           1.12340914e-03, -2.15944645e-04, -9.97532974e-04],\n",
       "         [-1.49018515e-03, -1.79674954e-03, -9.76388750e-04, ...,\n",
       "          -3.38565488e-03,  1.68341445e-03,  5.63292124e-04],\n",
       "         [ 2.42281565e-03, -1.53683568e-03, -1.00805529e-03, ...,\n",
       "          -1.69112766e-03,  1.55046245e-03,  1.97181222e-03]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-1.57741853e-03,  1.01039722e-03,  1.26976846e-03, ...,\n",
       "          -1.40784483e-04, -4.33607318e-04, -1.42979994e-03],\n",
       "         [ 3.45437613e-04, -3.27633275e-03,  6.56613789e-04, ...,\n",
       "          -3.18144448e-03,  6.81565667e-04,  1.80442969e-03],\n",
       "         [ 1.00107864e-03, -8.79700005e-04, -4.85178374e-04, ...,\n",
       "           4.67079168e-04,  2.04656157e-03, -9.97378258e-04],\n",
       "         ...,\n",
       "         [-8.78076651e-04, -2.84484960e-03, -7.20070850e-04, ...,\n",
       "           4.32038360e-04, -2.59463530e-04,  3.25153902e-04],\n",
       "         [-5.71330427e-04, -2.69743940e-03,  3.84420942e-04, ...,\n",
       "          -1.05938967e-03,  6.76328724e-04,  4.19450691e-03],\n",
       "         [ 9.86625440e-04,  4.86366625e-04, -3.04805988e-04, ...,\n",
       "          -2.24898933e-04, -1.37474411e-03, -1.16709317e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 1.63919781e-03,  1.90033310e-03, -1.25223165e-03, ...,\n",
       "           1.35293324e-03, -5.17308887e-04,  5.77257772e-04],\n",
       "         [ 1.15067465e-03,  2.38967035e-03,  7.33742316e-04, ...,\n",
       "           2.24241187e-04,  3.61701008e-04,  1.15744700e-03],\n",
       "         [ 7.90572783e-04,  1.85531820e-03, -9.30939917e-04, ...,\n",
       "          -2.21588925e-05, -1.10466545e-03,  7.53578148e-04],\n",
       "         ...,\n",
       "         [ 2.47074873e-04,  1.58007501e-03, -2.02845084e-03, ...,\n",
       "           1.24125450e-03, -1.10582868e-03,  1.30430772e-03],\n",
       "         [ 1.19339605e-03,  9.26036271e-04, -1.42483425e-03, ...,\n",
       "           1.06028235e-03, -6.19265309e-04, -5.16781176e-04],\n",
       "         [-9.25533357e-04,  1.34515716e-03,  9.26974579e-04, ...,\n",
       "           3.32631264e-03, -6.86084095e-05, -8.19712994e-04]]],\n",
       "\n",
       "\n",
       "       [[[ 1.90604653e-03,  1.01213669e-03,  2.85253947e-04, ...,\n",
       "           1.55299099e-03,  3.78235593e-03, -2.49474053e-03],\n",
       "         [-2.56609084e-04,  1.07006647e-03, -1.64849951e-03, ...,\n",
       "          -1.04502228e-03,  6.05351641e-04,  2.95154197e-04],\n",
       "         [-1.93294545e-03,  2.23789737e-03,  8.64927599e-04, ...,\n",
       "           1.58813864e-03, -1.38834224e-03,  7.62087293e-04],\n",
       "         ...,\n",
       "         [-1.15881010e-03,  3.63702257e-03,  1.31264701e-03, ...,\n",
       "           3.57034733e-04, -5.02625306e-04,  1.15292333e-03],\n",
       "         [ 1.28981730e-04, -1.21506990e-03,  1.18748308e-03, ...,\n",
       "          -4.63063370e-05, -1.35421066e-03, -1.82549946e-03],\n",
       "         [-6.18108781e-04, -1.48281513e-03,  7.97081564e-04, ...,\n",
       "          -7.60556286e-05,  1.69484687e-04,  2.42992234e-03]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_flat = tf.random.normal((54, 169, 32, 1), 0, .01)\n",
    "w_spatial_flat = tf.random.normal((169, 1, 1, 55), 0, .01)\n",
    "tf.nn.conv2d(conv_flat, w_spatial_flat, strides = [1,1,1,1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(54, 1, 32, 55), dtype=float32, numpy=\n",
       "array([[[[ 1.26850139e-03, -2.70349556e-03, -3.20244301e-03, ...,\n",
       "          -1.14344864e-03,  2.60487781e-03, -1.19431003e-03],\n",
       "         [ 2.12274259e-03,  2.57920055e-03,  1.58308540e-03, ...,\n",
       "           7.23338744e-04, -5.70198696e-04, -1.05345331e-03],\n",
       "         [ 1.64031831e-03,  1.79351788e-04, -1.02913077e-03, ...,\n",
       "           8.55317849e-05, -1.96256279e-03,  9.11435985e-04],\n",
       "         ...,\n",
       "         [ 1.98840979e-03,  3.93293012e-04,  1.34366433e-04, ...,\n",
       "           1.37273537e-03, -1.75602006e-04,  1.40861026e-04],\n",
       "         [ 2.24512233e-03,  6.86684973e-04,  7.31278051e-05, ...,\n",
       "           1.70216372e-03,  3.96068994e-04,  1.90826121e-03],\n",
       "         [-2.75617698e-03, -1.87044463e-03, -1.94357580e-03, ...,\n",
       "           6.30953757e-04,  1.67098839e-03,  1.53884757e-03]]],\n",
       "\n",
       "\n",
       "       [[[-1.23207679e-03, -1.91548810e-04, -1.95643865e-03, ...,\n",
       "          -2.64315953e-04,  1.83474983e-03, -9.24907508e-05],\n",
       "         [-5.19676250e-04,  1.09382276e-03, -7.94476218e-05, ...,\n",
       "          -1.17671897e-03, -1.53091527e-03, -2.94668530e-03],\n",
       "         [-3.79301928e-04,  1.29538367e-03, -4.01060825e-04, ...,\n",
       "           4.96318797e-04, -9.26797045e-04,  1.96734187e-03],\n",
       "         ...,\n",
       "         [-7.19393080e-04, -1.10808027e-03, -1.32705827e-04, ...,\n",
       "           5.24949792e-06, -8.05880758e-04,  6.13930752e-05],\n",
       "         [ 1.68714346e-03, -1.71369710e-03, -8.16670305e-04, ...,\n",
       "           1.92252424e-04, -9.52208415e-04, -1.58052891e-04],\n",
       "         [-8.22998059e-04, -1.00693235e-03, -2.02334748e-04, ...,\n",
       "           1.89124653e-03,  1.11248798e-03, -9.46551678e-04]]],\n",
       "\n",
       "\n",
       "       [[[-1.15793559e-03,  1.70757796e-03,  3.26212379e-04, ...,\n",
       "           2.11118744e-03, -1.80226145e-03,  6.57861470e-04],\n",
       "         [-1.16617116e-03, -1.01512752e-03,  9.57464508e-04, ...,\n",
       "           1.36222620e-03, -4.32343659e-04, -1.29453244e-03],\n",
       "         [ 1.97523530e-03, -1.94732484e-03,  3.08389962e-03, ...,\n",
       "           2.28198222e-03,  2.06316297e-04, -1.31088821e-03],\n",
       "         ...,\n",
       "         [-2.25653849e-03,  3.28447291e-04, -7.03365251e-04, ...,\n",
       "          -1.25442806e-03,  1.01848424e-03, -6.49670255e-05],\n",
       "         [-7.64002034e-04,  4.65544494e-04, -6.11189171e-04, ...,\n",
       "           7.91783852e-04, -3.06471658e-04,  1.34014792e-03],\n",
       "         [ 1.80441618e-03,  8.86941329e-04, -2.06121986e-04, ...,\n",
       "           1.44186674e-03,  8.40628345e-04, -8.40251625e-04]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 1.91297033e-03, -1.16829493e-03,  2.79722182e-04, ...,\n",
       "           5.99843566e-04, -5.02523792e-04, -9.97939715e-05],\n",
       "         [-2.18770024e-03,  2.49600387e-03, -4.48109466e-04, ...,\n",
       "           1.13228720e-03,  1.02379627e-03, -7.41470081e-04],\n",
       "         [ 5.82473993e-04, -5.75679704e-04, -2.60568480e-03, ...,\n",
       "           3.06401082e-04,  1.56414183e-03,  1.48855315e-05],\n",
       "         ...,\n",
       "         [ 1.69038613e-04, -5.94364363e-04,  6.98433549e-04, ...,\n",
       "          -2.84841895e-04,  9.79087199e-04,  2.28081961e-04],\n",
       "         [-1.94080028e-04, -1.20137795e-03, -6.16037403e-04, ...,\n",
       "           1.62734941e-04,  6.59114972e-04,  1.18442054e-03],\n",
       "         [ 6.76999218e-04,  9.68610111e-04, -2.21904018e-03, ...,\n",
       "           2.17487614e-04,  3.09729483e-04, -1.01475057e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 1.83212222e-03,  1.56479143e-03, -1.08280947e-04, ...,\n",
       "          -6.46609580e-04, -1.11165200e-03, -1.41802710e-04],\n",
       "         [-2.16380940e-04, -8.55975260e-04,  9.12842806e-04, ...,\n",
       "          -1.77963020e-03, -5.56146202e-04,  6.37091871e-04],\n",
       "         [ 3.09956231e-04, -7.05425860e-04, -1.19449955e-03, ...,\n",
       "           1.24639052e-03,  4.03478276e-03,  4.72867123e-06],\n",
       "         ...,\n",
       "         [ 2.31993687e-03,  8.04706942e-04,  1.49424234e-03, ...,\n",
       "           8.70000687e-04, -3.97249503e-04, -5.32781007e-04],\n",
       "         [ 6.29330345e-04,  1.50336151e-03, -1.37937069e-03, ...,\n",
       "          -1.33506337e-03,  8.57532083e-04,  1.37715624e-03],\n",
       "         [-2.26612887e-04,  6.33838295e-04, -8.78557446e-04, ...,\n",
       "          -1.12773769e-03,  1.46281411e-04, -1.74132909e-03]]],\n",
       "\n",
       "\n",
       "       [[[ 5.05281459e-05,  1.50352978e-04,  6.17025478e-04, ...,\n",
       "          -5.32783160e-04, -2.07557785e-03,  3.88826500e-03],\n",
       "         [ 1.42985524e-03, -1.30476255e-03,  1.31125282e-03, ...,\n",
       "          -3.10575560e-04, -1.36974384e-03, -1.08953856e-03],\n",
       "         [-1.96156441e-04, -1.50436928e-04, -1.51811133e-03, ...,\n",
       "           6.35385513e-04,  3.50765011e-04,  1.71325903e-03],\n",
       "         ...,\n",
       "         [ 4.62772179e-04, -2.65114912e-04, -8.34140694e-04, ...,\n",
       "           1.10987376e-03,  7.54058477e-04,  1.14538132e-04],\n",
       "         [-2.38368099e-04,  9.28897236e-04, -1.52719207e-03, ...,\n",
       "          -1.33013772e-03, -7.27601466e-04,  1.14016864e-03],\n",
       "         [ 6.40448066e-04,  3.81871825e-04, -2.79959699e-04, ...,\n",
       "          -6.07814058e-04, -1.79417885e-03, -1.50382170e-04]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=\n",
       "array([[[[10.       ,  1.9000001],\n",
       "         [10.       ,  2.2      ],\n",
       "         [ 6.       ,  1.6      ],\n",
       "         [ 6.       ,  2.       ]],\n",
       "\n",
       "        [[12.       ,  1.4      ],\n",
       "         [15.       ,  2.2      ],\n",
       "         [13.       ,  2.7      ],\n",
       "         [13.       ,  1.7      ]],\n",
       "\n",
       "        [[ 7.       ,  1.7      ],\n",
       "         [11.       ,  1.3      ],\n",
       "         [16.       ,  1.3000001],\n",
       "         [ 7.       ,  1.       ]],\n",
       "\n",
       "        [[10.       ,  0.6      ],\n",
       "         [ 7.       ,  1.4      ],\n",
       "         [ 4.       ,  1.5      ],\n",
       "         [ 7.       ,  1.4000001]]]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in = np.array([[\n",
    "  [[2], [1], [2], [0], [1]],\n",
    "  [[1], [3], [2], [2], [3]],\n",
    "  [[1], [1], [3], [3], [0]],\n",
    "  [[2], [2], [0], [1], [1]],\n",
    "  [[0], [0], [3], [1], [2]], ]])\n",
    "\n",
    "print(x_in.shape)\n",
    "\n",
    "kernel_in = np.array([\n",
    "    [ [[2, 0.1]], [[3, 0.2]] ],\n",
    "    [ [[0, 0.3]], [[1, 0.4]] ], ])\n",
    "x = tf.constant(x_in, dtype=tf.float32)\n",
    "kernel = tf.constant(kernel_in, dtype=tf.float32)\n",
    "tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-0.001621549>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.multiply(h_spatial, w_features), [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x180e94baeb0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.nn.functional.elu(torch.Tensor(list(np.arange(-5,5,.1)-1)))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lucent.modelzoo import inceptionv1, util\n",
    "from helper import makeGaussian, FeatureExtractor, fix_parameters, load_sta\n",
    "\n",
    "pretrained_model = inceptionv1(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = fix_parameters(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x00000264B79B5820>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model.modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d2\n",
      "RedirectedReluLayer()\n"
     ]
    }
   ],
   "source": [
    "inc = FeatureExtractor(ann, layers = ['conv2d2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:   conv2d2 <class 'str'>\n",
      "FTE:          ['conv2d2', 'mixed4d', 'mixed4a']\n",
      "conv in FTE True\n",
      "\n",
      "\n",
      "\n",
      "conv2d2\n",
      "RedirectedReluLayer()\n",
      "dict_keys(['conv2d2']) torch.Size([1, 192, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from helper import makeGaussian, FeatureExtractor, fix_parameters, load_sta\n",
    "from lucent.modelzoo import vgg19, inceptionv1, util\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class InceptionNet(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model, layer = 'conv2d2', num_neurons = 43, device = None):\n",
    "        super(InceptionNet, self).__init__()\n",
    "\n",
    "        self.features_to_extract = ['conv2d2', 'mixed4d', 'mixed4a']\n",
    "        self.layer = layer\n",
    "        print('Layer:  ', self.layer, type(self.layer))\n",
    "        print('FTE:         ', self.features_to_extract)\n",
    "        print('conv in FTE', self.layer in self.features_to_extract)\n",
    "        print('\\n\\n')\n",
    "\n",
    "        self.inception_pretrained = pretrained_model\n",
    "        self.ann = fix_parameters(self.inception_pretrained)\n",
    "        self.feature_extractor = FeatureExtractor(self.ann, layers = [self.layer])\n",
    "\n",
    "        dummy_input  = torch.ones(1, 3, 224, 224)\n",
    "        dummy_output = self.feature_extractor(dummy_input)\n",
    "        print(dummy_output.keys(), dummy_output[list(dummy_output.keys())[0]].shape)\n",
    "        dummy_output_shape = list(dummy_output[list(dummy_output.keys())[0]].shape)\n",
    "        self.w_shape = dummy_output_shape[1:] + [num_neurons]\n",
    "        self.w = dummy_output_shape\n",
    "        \n",
    "        \n",
    "    def shape(self):\n",
    "        return self.w\n",
    "    def mod_shape(self):\n",
    "        return self.w_shape\n",
    "\n",
    "    \n",
    "incept_pretrained = inceptionv1(pretrained = True)\n",
    "incept = InceptionNet(incept_pretrained)\n",
    "sw     = incept.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:   conv2d2 <class 'str'>\n",
      "FTE:          ['conv2d2', 'mixed4d', 'mixed4a']\n",
      "conv in FTE True\n",
      "\n",
      "\n",
      "\n",
      "conv2d2\n",
      "RedirectedReluLayer()\n",
      "dict_keys(['conv2d2']) torch.Size([1, 192, 56, 56])\n",
      "Layer:   mixed4d <class 'str'>\n",
      "FTE:          ['conv2d2', 'mixed4d', 'mixed4a']\n",
      "conv in FTE True\n",
      "\n",
      "\n",
      "\n",
      "mixed4d\n",
      "CatLayer()\n",
      "dict_keys(['mixed4d']) torch.Size([1, 528, 14, 14])\n",
      "Layer:   mixed4a <class 'str'>\n",
      "FTE:          ['conv2d2', 'mixed4d', 'mixed4a']\n",
      "conv in FTE True\n",
      "\n",
      "\n",
      "\n",
      "mixed4a\n",
      "CatLayer()\n",
      "dict_keys(['mixed4a']) torch.Size([1, 508, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "layers_list = ['conv2d2', 'mixed4d', 'mixed4a']\n",
    "\n",
    "for i in layers_list:\n",
    "    incept = InceptionNet(incept_pretrained, layer=i)\n",
    "    sw     = incept.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input  = torch.ones(1, 3, 224, 224)\n",
    "dummy_output = inc(dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 56, 56])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_output['conv2d2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {'a':1, 'b':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('a', 1), ('b', 2)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3', '4', '5678')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.match(r'ROI_(\\d+)_layer_(\\d+).(\\d+)_Vgg', 'ROI_3_layer_4.5678_Vgg').groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.1, 1.0, 0.01)\n",
      "1 (0.1, 1.0, 0.001)\n",
      "2 (0.1, 1.0, 0.0001)\n",
      "3 (0.1, 0.1, 0.01)\n",
      "4 (0.1, 0.1, 0.001)\n",
      "5 (0.1, 0.1, 0.0001)\n",
      "6 (0.1, 0.01, 0.01)\n",
      "7 (0.1, 0.01, 0.001)\n",
      "8 (0.1, 0.01, 0.0001)\n",
      "9 (0.01, 1.0, 0.01)\n",
      "10 (0.01, 1.0, 0.001)\n",
      "11 (0.01, 1.0, 0.0001)\n",
      "12 (0.01, 0.1, 0.01)\n",
      "13 (0.01, 0.1, 0.001)\n",
      "14 (0.01, 0.1, 0.0001)\n",
      "15 (0.01, 0.01, 0.01)\n",
      "16 (0.01, 0.01, 0.001)\n",
      "17 (0.01, 0.01, 0.0001)\n",
      "18 (0.001, 1.0, 0.01)\n",
      "19 (0.001, 1.0, 0.001)\n",
      "20 (0.001, 1.0, 0.0001)\n",
      "21 (0.001, 0.1, 0.01)\n",
      "22 (0.001, 0.1, 0.001)\n",
      "23 (0.001, 0.1, 0.0001)\n",
      "24 (0.001, 0.01, 0.01)\n",
      "25 (0.001, 0.01, 0.001)\n",
      "26 (0.001, 0.01, 0.0001)\n"
     ]
    }
   ],
   "source": [
    "sparsity       = [10e-2, 10e-3, 10e-4]\n",
    "smoothness     = [10e-1, 10e-2, 10e-3]\n",
    "group_sparsity = [10e-3, 10e-4, 10e-5]\n",
    "\n",
    "hyperparam_list = [sparsity, smoothness, group_sparsity]\n",
    "\n",
    "import itertools\n",
    "for n, i in enumerate(itertools.product(*hyperparam_list)):\n",
    "    print(n, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'value a is 1.000000e-05'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0.00001\n",
    "\n",
    "roi = 3\n",
    "layer = 14\n",
    "\n",
    "spa = 10e-3\n",
    "smo = 10e-2\n",
    "gsp = 10e-4\n",
    "\n",
    "import subprocess as sp\n",
    "sp.call(['python', 'train_cadena_model_vgg.py', '-r', str(roi), '-l', str(layer), '-spa', str(spa), '-smo', str(smo), '-gsp', str(gsp)], shell=True)\n",
    "\n",
    "#f'value a is {a:e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.system(' '.join(['python', 'train_cadena_model_vgg.py', '-r', str(roi), '-l', str(layer), '-spa', str(spa), '-smo', str(smo), '-gsp', str(gsp)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-4==1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "sp.call(['python', 'train_cadena_model_vgg', '-r', roi, '-l', layer, '-spa', spa, '-smo', smo, '-gsp', gsp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1ebba55313e133a64a1b90f6812a303e776c8bfea60a3ce9dccd29ed02aed0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
